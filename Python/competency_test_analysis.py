# Setups and Data

# imports
import os
import json
import pandas as pd
pd.options.display.float_format = '{:20,.2f}'.format
import numpy as np
from datetime import datetime, date, timedelta
import sys

# mount appropriate google drive and authenticate using instructions below
# this will show you the file system on the left under the folder icon
# from google.colab import drive
# drive.mount('/content/drive')

# import sys
# path_to_my_drive_folder = "/content/drive/My Drive/ASIST/Analysis"
# sys.path.append(path_to_my_drive_folder)

import myfunctions as f  # import functions for processing metadata

# Populate identifiers for different message and topic types
# see message_summary.md for details:
# https://drive.google.com/drive/u/1/folders/1QqY861SUTdQkCP2WelJbm4WNTOnlk97A

trial_identifier = '"message_type":"trial"'
score_identifier = '"topic":"observations/events/scoreboard"'
location_identifier = '"topic":"observations/events/player/location"'
triage_identifier =  '"topic":"observations/events/player/triage"'
mission_identifier = '"topic":"observations/events/mission"'
competencyTask_identifier = '"topic":"observations/events/competency/task"'
jumped_identifier = '"topic":"observations/events/player/jumped"'

# use the file system to copy and paste the exact filepath for the .metadata file you wish to open
# location that stores all .metadata files from participant competency tests
# competency_dir = '/home/erik_jones/git/asist_data/competency_data' # REPLACE with your directory path
root_dir = '/mnt/DARPA/CONSULTING/Analytics/Phase_1/Data'
competency_dir = f'{root_dir}/competency_data'

# Competency Test Data Analysis
# Create dataframe with task completion times: participant x task_id
df = pd.DataFrame(index=range(0,16))

for subdir, dirs, files in os.walk(competency_dir):

  for i, file in enumerate(files):
    if i == 2: break
    print('Loading', i, 'of', len(files))
    filepath = subdir + os.sep + file
    id = file.split('.')[0]
    messages = f.loadMetadata(filepath)
    timing = f.competencyTestState(messages, competencyTask_identifier)
    df = pd.concat([df, timing['timeSpent']], axis=1)
    df = df.rename(columns={'timeSpent': id})

df.index.name = 'task_id'
df = df.loc[1:14]
df.loc['total'] = df.sum()

# manually add 2 tasks times for rescue skills
# saving victims is homogeneous and predetermined in this version
df.loc[15] = 7.5
df.loc[16] = 15

df = df.reindex(sorted(df.columns), axis=1)

# read skill requirements for each subtask (external file; manually created)
# skill_req = f.readDfFromGSheetTab('competency_data_analysis','competency_skills')
skill_req = pd.read_excel('competency_data_analysis.xlsx', sheet_name='competency_skills')
skill_req = skill_req.iloc[:-1]
skill_req['task_id'] = skill_req['task_id'].astype(float)

# prep participant completion times
dt = df.drop('total').reset_index()
dt['task_id'] = dt['task_id'].astype(float)

# create system of equations
# 4 eqns are generated by collapsing competency tasks times by unique search skill combos assessed in each task
x = pd.merge(skill_req, dt, on='task_id').set_index('task_id')
x = x.drop(columns=['task_name']).apply(pd.to_numeric)
eq = x.groupby('unique_skills_assessed')[x.columns[1:]].sum()
eq = eq.loc[1:] # drop redundant col

score = pd.DataFrame(columns=eq.columns[0:6])
for p in eq.columns[-6:]:
  score.loc[p] = np.linalg.solve(eq[eq.columns[0:6]].to_numpy(dtype=np.float),eq[p].to_numpy(dtype=np.float))
score = score.T
score.loc['aggregate_time'] = df.loc['total']

# f.writeDfToGSheetTab('competency_data_analysis', 'skill_estimates', score)
print(score.to_string())

# Interpretation of Skill Estimates
#- Each cell indicates the a skill index in terms of time impact on performance for each instance of skill is used during a task.
#- Example 1: walk = 0.36 means this player requires addition 0.36s for each step they need to take.
#- Example 2: obstacle = -0.39 means this player saves 0.39s for each obstacle they jump over (may indicate they are better at jumping over 3-4 blocks as against walking 3-4 blocks)
#- Note rescue skills are static by tasks design. In the future this may be varied across participants.
